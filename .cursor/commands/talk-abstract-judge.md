Evaluate a talk abstract using the scoring framework below.

I will provide the abstract and any context about the talk. Score it systematically against all metrics, then provide structured feedback.

# Talk Abstract Evaluation

Score the abstract on a 110-point scale (100 base + 10 bonus) across 4 categories. Use the rubrics below — not gut feel. Reference specific sentences/phrases when scoring.

---

## Category 1: Style Authenticity (40 points)

### 1.1 Voice Consistency (0-10)
How closely the writing matches Dominik Schmidle's authentic voice.

| Score | Level | Description |
|-------|-------|-------------|
| 9-10 | Authentic | Indistinguishable from Dominik's writing. Natural flow, characteristic phrases |
| 7-8 | Very Close | Mostly authentic with 1-2 "off" moments |
| 5-6 | Recognizable | Core voice there but feels slightly AI-polished |
| 3-4 | Generic | Standard tech writing, loses distinctive voice |
| 0-2 | Off-Brand | Does not sound like Dominik |

Check: Conversational not corporate? Authentic enthusiasm without hype? Natural personal pronouns? No buzzword stacking? Sentence variety?

### 1.2 Tone Alignment (0-10)
Balance of professional + approachable + humble + enthusiastic.

Check: Honest about challenges? Confident without arrogance? Optimistic and solutions-focused? Self-aware? Professional but warm?

### 1.3 Language Patterns (0-10)
Use of characteristic vocabulary, phrases, and structures.

Check: Technical terms natural not forced? Transformation narratives ("from X to Y")? Real-world framing? Avoids "leverage", "synergy", "best-in-class", "cutting-edge", "game-changer"? Prefers "practical", "real-world", "journey", "patterns", "lessons learned"?

### 1.4 Structural Flow (0-10)
Narrative arc and progression.

Check: Opens with relatable problem? Builds through transformation? Concrete metrics mid-way? Ends with value proposition? Natural transitions (not "Additionally", "Furthermore", "Moreover")?

---

## Category 2: Content Quality (35 points)

### 2.1 Narrative Strength (0-10)
Compelling story arc and transformation journey.

Check: Clear "before" state? Transformation journey? "After" state? Unexpected elements? Human elements beyond just technical?

### 2.2 Concrete Specificity (0-10)
Real numbers, specific examples, tangible details.

**Good specifics (easily provable):** team size, cluster/customer counts, geographic reach, timeframes, named tech stacks.

**Avoid:** percentage improvements without baseline, vague comparisons, unverifiable claims.

**⚠️ INVENTED SPECIFICS = automatic -10 points.** If numbers seem made up or weren't provided in context, flag immediately.

### 2.3 Value Clarity (0-10)
How clear it is who this is for and what they'll get.

Check: Target audience explicit? Specific takeaways? Actionable outcomes? Clear differentiation? Transferable patterns offered?

### 2.4 Technical Credibility (0-5)
Technical accuracy and appropriate depth.

Check: Technology names correct? Architectural concepts accurate? Scale claims realistic? Tool names precise? No impossible claims?

---

## Category 3: Professional Standards (25 points)

### 3.1 Conference Appropriateness (0-10)
Fit for professional conference submission.

Check: Correct perspective (3rd person if required)? Appropriate length? No sales language? Honest about scope? Grammar/spelling perfect?

### 3.2 Audience Targeting (0-8)
Clear identification of who should attend and why.

Check: Specific roles mentioned? Experience level implied? Problem alignment? Clear exclusions? Outcome match?

### 3.3 Differentiation (0-7)
Unique perspective and value through positive framing.

**Good differentiation:**
- ✅ "From a Product Manager's perspective..."
- ✅ "Drawing from workshops with dozens of organizations..."
- ✅ "This isn't a technical deep-dive but focuses on organizational strategy"

**Bad differentiation:**
- ❌ "Most talks fail to address..." (dismissive)
- ❌ "Other talks are missing..." (arrogant)

---

## Category 4: Impact Potential (Bonus, up to 10 points)

### 4.1 Memorability (0-5)
Provocative opening? Memorable facts? Honest vulnerability? Unexpected outcomes? Clear takeaway framework?

### 4.2 Community Value (0-5)
Transferable patterns? Fills knowledge gap? Helps others avoid mistakes? Shares frameworks? Advances industry thinking?

---

## Red Flags (Automatic Score Reductions, -5 to -10 each)

**Voice/Style:** Uses "leverage"/"synergy"/"game-changing". Overly formal/academic. Sales pitch tone. No personality. Buzzword bingo (5+).

**Content:** No concrete metrics. Vague claims. Impossible claims. Technical inaccuracies. No value proposition. **Invented specifics (-10).**

**Professional:** Grammar/spelling errors. Unclear audience. Generic (could be any talk). Promotional language. Wrong perspective.

---

## Score Interpretation

| Score | Rating | Action |
|-------|--------|--------|
| 95-110 | Excellent | Submit immediately |
| 85-94 | Strong | Minor polish needed |
| 70-84 | Good | Targeted improvements needed |
| 50-69 | Adequate | Significant style or content work |
| Below 50 | Weak | Major revision or restart |

---

## Output Format

Provide feedback in this exact structure:

```
TOTAL SCORE: XX/110 (XX%)

CATEGORY BREAKDOWN:
- Style Authenticity: XX/40
- Content Quality: XX/35
- Professional Standards: XX/25
- Impact Potential: XX/10

TOP STRENGTHS:
1. [Specific strength with quoted example]
2. [Specific strength with quoted example]

CRITICAL IMPROVEMENTS NEEDED:
1. [Specific issue with quoted example and suggested fix]
2. [Specific issue with quoted example and suggested fix]

STYLE ALIGNMENT:
[How close to Dominik's voice, with specific examples of what works and what's off]

RECOMMENDATION:
[Ready to submit / Needs refinement / Needs major revision]
```

---

## Iteration Guidance

If score is below 85:
1. Identify the lowest-scoring category
2. Focus improvements on that area first
3. Rewrite (don't patch) to maintain natural flow
4. Re-score after changes

Typical pattern: first draft 60-75 → second 75-85 → third 85-95 → fourth 95+
